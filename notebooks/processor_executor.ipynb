{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processor/Executor - Event Processing with Flow-Based State Tracking\n",
    "\n",
    "The **Processor/Executor** pattern provides production-grade event processing with:\n",
    "- **Priority Queue**: Lower priority values processed first\n",
    "- **Capacity Control**: Rate limiting with refresh intervals\n",
    "- **Flow-Based State**: O(1) status queries via EventStatus-aligned progressions\n",
    "- **Background Processing**: Continuous execution with `execute()`\n",
    "- **Permission Checks**: Override `request_permission()` for custom gating\n",
    "\n",
    "**Architecture**:\n",
    "- `Executor`: Flow-based state management (1:1 EventStatus mapping)\n",
    "- `Processor`: Priority queue + background processing\n",
    "- `Flow.progressions`: One progression per EventStatus value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import asyncio\n",
    "from typing import Any, ClassVar\n",
    "\n",
    "from lionpride.core import Event, EventStatus, Executor, Processor\n",
    "\n",
    "\n",
    "# Define test events\n",
    "class SimpleEvent(Event):\n",
    "    \"\"\"Basic event for testing.\"\"\"\n",
    "\n",
    "    task_name: str = \"task\"\n",
    "    result: int = 0\n",
    "\n",
    "    async def _invoke(self):\n",
    "        await asyncio.sleep(0.01)  # Simulate work\n",
    "        return self.result\n",
    "\n",
    "\n",
    "class SimpleProcessor(Processor):\n",
    "    \"\"\"Basic processor for SimpleEvent.\"\"\"\n",
    "\n",
    "    event_type: ClassVar[type[Event]] = SimpleEvent\n",
    "\n",
    "\n",
    "class SimpleExecutor(Executor):\n",
    "    \"\"\"Basic executor for SimpleEvent.\"\"\"\n",
    "\n",
    "    processor_type: ClassVar[type[Processor]] = SimpleProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Executor Setup\n",
    "\n",
    "Create executor with processor configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor: Executor(total=0, pending=0, processing=0, completed=0, failed=0, cancelled=0, skipped=0, aborted=0)\n",
      "Event type: <class '__main__.SimpleEvent'>\n",
      "Progressions: ['pending', 'processing', 'completed', 'failed', 'cancelled', 'skipped', 'aborted']\n",
      "\n",
      "Status counts: {'pending': 0, 'processing': 0, 'completed': 0, 'failed': 0, 'cancelled': 0, 'skipped': 0, 'aborted': 0}\n"
     ]
    }
   ],
   "source": [
    "# Create executor with processor config\n",
    "executor = SimpleExecutor(\n",
    "    processor_config={\n",
    "        \"queue_capacity\": 10,  # Process 10 events per batch\n",
    "        \"capacity_refresh_time\": 0.1,  # 100ms between batches\n",
    "        \"concurrency_limit\": 5,  # Max 5 concurrent executions\n",
    "    },\n",
    "    name=\"simple_executor\",\n",
    ")\n",
    "\n",
    "print(f\"Executor: {executor}\")\n",
    "print(f\"Event type: {executor.event_type}\")\n",
    "print(f\"Progressions: {[p.name for p in executor.states.progressions]}\")\n",
    "print(f\"\\nStatus counts: {executor.status_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Event Queueing and Priority\n",
    "\n",
    "Add events with priority values (lower = higher priority)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor after append: Executor(total=3, pending=3, processing=0, completed=0, failed=0, cancelled=0, skipped=0, aborted=0)\n",
      "Pending events: 3\n",
      "  - low_priority: ab8b8904-f441-4cc2-b402-be4f0b23455f\n",
      "  - high_priority: 8ba64e7e-41b7-4a33-88cf-bfa727ad4ff1\n",
      "  - medium_priority: d1145746-962b-4348-8145-75cff3aafa2c\n"
     ]
    }
   ],
   "source": [
    "# Create events with different priorities\n",
    "events = [\n",
    "    SimpleEvent(task_name=\"low_priority\", result=1),\n",
    "    SimpleEvent(task_name=\"high_priority\", result=2),\n",
    "    SimpleEvent(task_name=\"medium_priority\", result=3),\n",
    "]\n",
    "\n",
    "# Add to executor with priorities (lower = processed first)\n",
    "await executor.append(events[0], priority=10.0)  # Low priority\n",
    "await executor.append(events[1], priority=1.0)  # High priority\n",
    "await executor.append(events[2], priority=5.0)  # Medium priority\n",
    "\n",
    "print(f\"Executor after append: {executor}\")\n",
    "print(f\"Pending events: {len(executor.pending_events)}\")\n",
    "\n",
    "# Events are in Flow.items pile\n",
    "for event in executor.pending_events:\n",
    "    print(f\"  - {event.task_name}: {event.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Status Queries (O(1))\n",
    "\n",
    "Query events by status using Flow progressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status queries:\n",
      "  Pending: 0\n",
      "  Processing: 0\n",
      "  Completed: 3\n",
      "  Failed: 0\n",
      "\n",
      "Completed events:\n",
      "  - low_priority: result=1\n",
      "  - high_priority: result=2\n",
      "  - medium_priority: result=3\n",
      "\n",
      "Executor State (simple_executor):\n",
      "  pending: 0 events\n",
      "  processing: 0 events\n",
      "  completed: 3 events\n",
      "  failed: 0 events\n",
      "  cancelled: 0 events\n",
      "  skipped: 0 events\n",
      "  aborted: 0 events\n"
     ]
    }
   ],
   "source": [
    "# Start executor to initialize processor\n",
    "await executor.start()\n",
    "\n",
    "# Process events manually (one batch)\n",
    "await executor.forward()\n",
    "await asyncio.sleep(0.05)  # Let events complete\n",
    "\n",
    "# O(1) status queries via Flow progressions\n",
    "print(\"Status queries:\")\n",
    "print(f\"  Pending: {len(executor.pending_events)}\")\n",
    "print(f\"  Processing: {len(executor.processing_events)}\")\n",
    "print(f\"  Completed: {len(executor.completed_events)}\")\n",
    "print(f\"  Failed: {len(executor.failed_events)}\")\n",
    "\n",
    "# Get events by status\n",
    "completed = executor.get_events_by_status(EventStatus.COMPLETED)\n",
    "print(\"\\nCompleted events:\")\n",
    "for event in completed:\n",
    "    print(f\"  - {event.task_name}: result={event.execution.response}\")\n",
    "\n",
    "# Inspect full state\n",
    "print(f\"\\n{executor.inspect_state()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Custom Permission Checks\n",
    "\n",
    "Override `request_permission()` for rate limiting, auth, quotas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permission granted: 1/2\n",
      "Permission granted: 2/2\n",
      "Rate limit exceeded: 2/2\n",
      "\n",
      "Final state: Executor(total=4, pending=2, processing=0, completed=2, failed=0, cancelled=0, skipped=0, aborted=0)\n",
      "Completed: 2\n",
      "Pending: 2\n"
     ]
    }
   ],
   "source": [
    "# Custom processor with rate limiting\n",
    "class RateLimitedProcessor(SimpleProcessor):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.request_count = 0\n",
    "        self.max_requests = 2  # Allow only 2 requests\n",
    "\n",
    "    async def request_permission(self, **kwargs: Any) -> bool:\n",
    "        # Custom permission check\n",
    "        if self.request_count >= self.max_requests:\n",
    "            print(f\"Rate limit exceeded: {self.request_count}/{self.max_requests}\")\n",
    "            return False\n",
    "        self.request_count += 1\n",
    "        print(f\"Permission granted: {self.request_count}/{self.max_requests}\")\n",
    "        return True\n",
    "\n",
    "\n",
    "class RateLimitedExecutor(Executor):\n",
    "    processor_type: ClassVar[type[Processor]] = RateLimitedProcessor\n",
    "\n",
    "\n",
    "# Test rate limiting\n",
    "rate_executor = RateLimitedExecutor(\n",
    "    processor_config={\n",
    "        \"queue_capacity\": 10,\n",
    "        \"capacity_refresh_time\": 0.1,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add 4 events (only 2 will be processed)\n",
    "for i in range(4):\n",
    "    await rate_executor.append(SimpleEvent(task_name=f\"task_{i}\", result=i))\n",
    "\n",
    "await rate_executor.start()\n",
    "await rate_executor.forward()\n",
    "await asyncio.sleep(0.05)\n",
    "\n",
    "print(f\"\\nFinal state: {rate_executor}\")\n",
    "print(f\"Completed: {len(rate_executor.completed_events)}\")\n",
    "print(f\"Pending: {len(rate_executor.pending_events)}\")\n",
    "# Note: Denied events are requeued with backoff (3 attempts before ABORTED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Concurrency Control\n",
    "\n",
    "Control concurrent executions with semaphore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max concurrent executions: 2 (limit was 2)\n",
      "Completed: 5\n"
     ]
    }
   ],
   "source": [
    "# Track concurrent executions\n",
    "active_count = 0\n",
    "max_concurrent = 0\n",
    "\n",
    "\n",
    "class ConcurrencyTrackingEvent(Event):\n",
    "    async def _invoke(self):\n",
    "        global active_count, max_concurrent\n",
    "        active_count += 1\n",
    "        max_concurrent = max(max_concurrent, active_count)\n",
    "        await asyncio.sleep(0.02)  # Simulate work\n",
    "        active_count -= 1\n",
    "        return \"done\"\n",
    "\n",
    "\n",
    "class ConcurrencyProcessor(Processor):\n",
    "    event_type: ClassVar[type[Event]] = ConcurrencyTrackingEvent\n",
    "\n",
    "\n",
    "class ConcurrencyExecutor(Executor):\n",
    "    processor_type: ClassVar[type[Processor]] = ConcurrencyProcessor\n",
    "\n",
    "\n",
    "# Test with concurrency_limit=2\n",
    "conc_executor = ConcurrencyExecutor(\n",
    "    processor_config={\n",
    "        \"queue_capacity\": 10,\n",
    "        \"capacity_refresh_time\": 0.1,\n",
    "        \"concurrency_limit\": 2,  # Max 2 concurrent\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add 5 events\n",
    "for _ in range(5):\n",
    "    await conc_executor.append(ConcurrencyTrackingEvent())\n",
    "\n",
    "await conc_executor.start()\n",
    "await conc_executor.forward()\n",
    "await asyncio.sleep(0.15)  # Wait for completion\n",
    "\n",
    "print(f\"Max concurrent executions: {max_concurrent} (limit was 2)\")\n",
    "print(f\"Completed: {len(conc_executor.completed_events)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Streaming Events\n",
    "\n",
    "Process streaming events with async generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming event status: pending\n",
      "Chunks streamed: 3\n",
      "Completed: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lion/projects/open-source/lionpride/src/lionpride/base/processor.py:257: RuntimeWarning: coroutine 'Event.stream' was never awaited\n",
      "  async for _ in event.stream():\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "# Streaming event\n",
    "class StreamingEvent(Event):\n",
    "    chunk_count: int = 3\n",
    "    streaming: bool = True  # Enable streaming mode\n",
    "\n",
    "    async def _invoke(self):\n",
    "        # This won't be called for streaming events\n",
    "        return \"not_used\"\n",
    "\n",
    "    async def _stream(self):\n",
    "        for i in range(self.chunk_count):\n",
    "            await asyncio.sleep(0.01)\n",
    "            yield f\"chunk_{i}\"\n",
    "\n",
    "\n",
    "class StreamingProcessor(Processor):\n",
    "    event_type: ClassVar[type[Event]] = StreamingEvent\n",
    "\n",
    "\n",
    "class StreamingExecutor(Executor):\n",
    "    processor_type: ClassVar[type[Processor]] = StreamingProcessor\n",
    "\n",
    "\n",
    "# Test streaming\n",
    "stream_executor = StreamingExecutor(\n",
    "    processor_config={\n",
    "        \"queue_capacity\": 5,\n",
    "        \"capacity_refresh_time\": 0.1,\n",
    "    }\n",
    ")\n",
    "\n",
    "stream_event = StreamingEvent(chunk_count=3)\n",
    "await stream_executor.append(stream_event)\n",
    "\n",
    "await stream_executor.start()\n",
    "await stream_executor.forward()\n",
    "await asyncio.sleep(0.05)  # Let stream complete\n",
    "\n",
    "print(f\"Streaming event status: {stream_event.status}\")\n",
    "print(f\"Chunks streamed: {stream_event.chunk_count}\")\n",
    "print(f\"Completed: {len(stream_executor.completed_events)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Manual vs Background Processing\n",
    "\n",
    "Choose between manual batch processing or continuous background execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before forward():\n",
      "  Pending: 3\n",
      "  Completed: 0\n",
      "\n",
      "After forward():\n",
      "  Pending: 0\n",
      "  Completed: 3\n",
      "\n",
      "Background execution:\n",
      "  Completed: 3\n",
      "  Processor stopped: True\n"
     ]
    }
   ],
   "source": [
    "# Manual processing (call forward() explicitly)\n",
    "manual_executor = SimpleExecutor(\n",
    "    processor_config={\"queue_capacity\": 5, \"capacity_refresh_time\": 0.1}\n",
    ")\n",
    "\n",
    "for i in range(3):\n",
    "    await manual_executor.append(SimpleEvent(task_name=f\"manual_{i}\"))\n",
    "\n",
    "await manual_executor.start()\n",
    "print(\"Before forward():\")\n",
    "print(f\"  Pending: {len(manual_executor.pending_events)}\")\n",
    "print(f\"  Completed: {len(manual_executor.completed_events)}\")\n",
    "\n",
    "await manual_executor.forward()  # Process batch manually\n",
    "await asyncio.sleep(0.05)\n",
    "\n",
    "print(\"\\nAfter forward():\")\n",
    "print(f\"  Pending: {len(manual_executor.pending_events)}\")\n",
    "print(f\"  Completed: {len(manual_executor.completed_events)}\")\n",
    "\n",
    "# Background processing (continuous execution)\n",
    "bg_executor = SimpleExecutor(processor_config={\"queue_capacity\": 5, \"capacity_refresh_time\": 0.05})\n",
    "\n",
    "for i in range(3):\n",
    "    await bg_executor.append(SimpleEvent(task_name=f\"bg_{i}\"))\n",
    "\n",
    "# Must call start() to create processor\n",
    "await bg_executor.start()\n",
    "\n",
    "# Start background execution\n",
    "exec_task = asyncio.create_task(bg_executor.processor.execute())\n",
    "\n",
    "await asyncio.sleep(0.2)  # Let background processor run\n",
    "await bg_executor.stop()\n",
    "await exec_task  # Wait for cleanup\n",
    "\n",
    "print(\"\\nBackground execution:\")\n",
    "print(f\"  Completed: {len(bg_executor.completed_events)}\")\n",
    "print(f\"  Processor stopped: {bg_executor.processor.is_stopped()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. State Serialization\n",
    "\n",
    "Serialize executor state for persistence and recovery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original executor:\n",
      "  Executor(total=5, pending=0, processing=0, completed=5, failed=0, cancelled=0, skipped=0, aborted=0)\n",
      "  Status counts: {'pending': 0, 'processing': 0, 'completed': 5, 'failed': 0, 'cancelled': 0, 'skipped': 0, 'aborted': 0}\n",
      "\n",
      "Serialized state keys: ['id', 'created_at', 'metadata', 'name', 'items', 'progressions']\n",
      "  Items: 6\n",
      "  Progressions: 6\n",
      "\n",
      "Restored Flow:\n",
      "  Name: serializable_exec\n",
      "  Items: 5\n",
      "  Progressions: ['pending', 'processing', 'completed', 'failed', 'cancelled', 'skipped', 'aborted']\n",
      "  pending: 0 events\n",
      "  processing: 0 events\n",
      "  completed: 5 events\n",
      "  failed: 0 events\n",
      "  cancelled: 0 events\n",
      "  skipped: 0 events\n",
      "  aborted: 0 events\n"
     ]
    }
   ],
   "source": [
    "# Create executor with events\n",
    "serializable_executor = SimpleExecutor(\n",
    "    processor_config={\"queue_capacity\": 5, \"capacity_refresh_time\": 0.1},\n",
    "    name=\"serializable_exec\",\n",
    ")\n",
    "\n",
    "# Add events and process some\n",
    "for _ in range(5):\n",
    "    await serializable_executor.append(SimpleEvent(task_name=f\"task_{i}\", result=i * 10))\n",
    "\n",
    "await serializable_executor.start()\n",
    "await serializable_executor.forward()\n",
    "await asyncio.sleep(0.05)\n",
    "\n",
    "print(\"Original executor:\")\n",
    "print(f\"  {serializable_executor}\")\n",
    "print(f\"  Status counts: {serializable_executor.status_counts()}\")\n",
    "\n",
    "# Serialize Flow state (events + progressions)\n",
    "state_data = serializable_executor.states.to_dict()\n",
    "print(f\"\\nSerialized state keys: {list(state_data.keys())}\")\n",
    "print(f\"  Items: {len(state_data['items'])}\")\n",
    "print(f\"  Progressions: {len(state_data['progressions'])}\")\n",
    "\n",
    "# Restore from serialized state\n",
    "from lionpride.core import Flow\n",
    "\n",
    "restored_flow = Flow.from_dict(state_data)\n",
    "print(\"\\nRestored Flow:\")\n",
    "print(f\"  Name: {restored_flow.name}\")\n",
    "print(f\"  Items: {len(restored_flow.items)}\")\n",
    "print(f\"  Progressions: {[p.name for p in restored_flow.progressions]}\")\n",
    "\n",
    "# Verify progression integrity\n",
    "for status in EventStatus:\n",
    "    prog = restored_flow.get_progression(status.value)\n",
    "    events = [restored_flow.items[uid] for uid in prog.order]\n",
    "    print(f\"  {status.value}: {len(events)} events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Processor/Executor Pattern**:\n",
    "\n",
    "1. **Basic Setup**: Executor with processor_config (queue_capacity, capacity_refresh_time, concurrency_limit)\n",
    "2. **Priority Queue**: Lower priority values processed first (default: created_at timestamp)\n",
    "3. **O(1) Status Queries**: Flow progressions map 1:1 with EventStatus enum\n",
    "4. **Permission Checks**: Override `request_permission()` for rate limiting, auth, quotas\n",
    "5. **Concurrency Control**: Semaphore limits concurrent executions (default: 100)\n",
    "6. **Streaming Support**: Events with `streaming=True` consume async generators\n",
    "7. **Processing Modes**: Manual (`forward()`) or background (`execute()`)\n",
    "8. **Serialization**: Flow.to_dict() captures full state (events + progressions)\n",
    "\n",
    "**Key Invariants**:\n",
    "- Events stored in Flow.items (single source of truth)\n",
    "- Progressions track event status (1:1 mapping with EventStatus)\n",
    "- Permission denials trigger 3 retries with backoff before ABORTED\n",
    "- Capacity resets after each batch (controlled by capacity_refresh_time)\n",
    "\n",
    "**Production Patterns**:\n",
    "- Use `cleanup_events()` to remove completed/failed events\n",
    "- Monitor with `status_counts()` and `inspect_state()`\n",
    "- Implement custom Processor for domain-specific permission checks\n",
    "- Serialize state periodically for crash recovery"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lionpride",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
