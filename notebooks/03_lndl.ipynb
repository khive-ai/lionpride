{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LNDL - Cognitive Programming Language for LLM Structured Output\n",
    "\n",
    "LNDL (Lion Natural Declaration Language) is a cognitive programming language that enables LLMs to:\n",
    "- **Think naturally** with prose, reasoning, and revisions\n",
    "- **Declare structured data** via explicit field mapping\n",
    "- **Execute actions lazily** (only when referenced in output)\n",
    "- **Control execution flow** with yields and continuations\n",
    "\n",
    "This notebook covers:\n",
    "1. LNDL syntax and semantics\n",
    "2. Parsing LNDL responses\n",
    "3. Using LNDL with lionpride operations\n",
    "4. ReAct loops with tool calling\n",
    "5. LNDL v2 cognitive extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from lionpride.lndl import (\n",
    "    Lexer,\n",
    "    Parser,\n",
    "    Program,\n",
    "    get_lndl_system_prompt,\n",
    "    parse_lndl,\n",
    "    parse_lndl_fuzzy,\n",
    ")\n",
    "from lionpride.types import Operable, Spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. LNDL Syntax Overview\n",
    "\n",
    "LNDL allows LLMs to intermix natural reasoning with structured declarations.\n",
    "\n",
    "### Core Constructs\n",
    "\n",
    "| Construct | Syntax | Purpose |\n",
    "|-----------|--------|--------|\n",
    "| Variable | `<lvar Model.field alias>value</lvar>` | Declare structured data |\n",
    "| Raw Variable | `<lvar alias>value</lvar>` | Simple string capture |\n",
    "| Action | `<lact name>function(args)</lact>` | Tool/function call |\n",
    "| Output | `OUT{field:[vars], scalar:literal}` | Final structured result |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the LNDL system prompt (sent to LLM as guidance)\n",
    "system_prompt = get_lndl_system_prompt()\n",
    "print(f\"System prompt: {len(system_prompt)} chars, {len(system_prompt.splitlines())} lines\")\n",
    "print(\"\\n--- First 500 chars ---\")\n",
    "print(system_prompt[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LNDL Variables - Explicit Field Mapping\n",
    "\n",
    "Variables use `Model.field` namespacing for explicit mapping to Pydantic models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example LNDL response from an LLM\n",
    "lndl_response = \"\"\"\n",
    "Let me analyze this step by step.\n",
    "\n",
    "First, I'll create a title:\n",
    "<lvar Report.title t1>AI Safety Overview</lvar>\n",
    "\n",
    "Actually, let me be more specific:\n",
    "<lvar Report.title t2>Comprehensive AI Safety Analysis for 2025</lvar>\n",
    "\n",
    "Now for the summary:\n",
    "<lvar Report.summary s>This report examines current AI safety practices,\n",
    "identifying key challenges and opportunities for improvement.</lvar>\n",
    "\n",
    "And a confidence score:\n",
    "<lvar Report.confidence c>0.85</lvar>\n",
    "\n",
    "Final output (using refined title t2):\n",
    "```lndl\n",
    "OUT{report:[t2, s, c]}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "print(\"LNDL Response Example:\")\n",
    "print(lndl_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the LNDL response\n",
    "lexer = Lexer(lndl_response)\n",
    "tokens = lexer.tokenize()\n",
    "parser = Parser(tokens, source_text=lndl_response)\n",
    "program: Program = parser.parse()\n",
    "\n",
    "print(\"Parsed LNDL Program:\")\n",
    "print(f\"  Variables (lvars): {len(program.lvars)}\")\n",
    "for lvar in program.lvars:\n",
    "    print(f\"    - {lvar.model}.{lvar.field} as '{lvar.alias}': {lvar.content[:50]}...\")\n",
    "\n",
    "print(f\"\\n  Actions (lacts): {len(program.lacts)}\")\n",
    "print(f\"\\n  Output block: {program.out_block}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LNDL Actions - Lazy Execution\n",
    "\n",
    "Actions are **only executed if referenced in OUT{}** - unreferenced actions are scratch work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with actions\n",
    "lndl_with_actions = \"\"\"\n",
    "Let me search for relevant information:\n",
    "\n",
    "<lact broad>search(query=\"AI\", limit=1000)</lact>\n",
    "That's too broad. Let me narrow it:\n",
    "\n",
    "<lact focused>search(query=\"AI safety research 2025\", limit=20)</lact>\n",
    "Better! Now I'll analyze:\n",
    "\n",
    "<lvar Report.title t>AI Safety Research Summary</lvar>\n",
    "<lvar Report.summary s>Based on search results...</lvar>\n",
    "\n",
    "```lndl\n",
    "OUT{report:[t, s], data:[focused]}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "lexer = Lexer(lndl_with_actions)\n",
    "parser = Parser(lexer.tokenize(), source_text=lndl_with_actions)\n",
    "program = parser.parse()\n",
    "\n",
    "print(\"Actions declared:\")\n",
    "for lact in program.lacts:\n",
    "    print(f\"  - {lact.alias}: {lact.call}\")\n",
    "\n",
    "print(f\"\\nOUT block references: {program.out_block.fields if program.out_block else 'None'}\")\n",
    "print(\"\\nExecution behavior:\")\n",
    "print(\"  - 'focused' EXECUTES (in OUT{})\")\n",
    "print(\"  - 'broad' NOT executed (scratch work)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Resolving LNDL to Pydantic Models\n",
    "\n",
    "Use `parse_lndl` to resolve LNDL output to validated Pydantic models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target Pydantic model\n",
    "class Report(BaseModel):\n",
    "    \"\"\"Analysis report model.\"\"\"\n",
    "\n",
    "    title: str = Field(..., description=\"Report title\")\n",
    "    summary: str = Field(..., description=\"Report summary\")\n",
    "    confidence: float = Field(default=0.5, ge=0.0, le=1.0)\n",
    "\n",
    "\n",
    "# Create an Operable to define the expected output structure\n",
    "report_operable = Operable(\n",
    "    specs=[\n",
    "        Spec(Report, name=\"report\"),\n",
    "    ],\n",
    "    name=\"ReportOutput\",\n",
    ")\n",
    "\n",
    "print(f\"Operable: {report_operable.name}\")\n",
    "print(f\"Specs: {[s.name for s in report_operable.get_specs()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse LNDL and resolve to model\n",
    "lndl_simple = \"\"\"\n",
    "<lvar Report.title t>AI Safety in Modern Systems</lvar>\n",
    "<lvar Report.summary s>This report provides an overview of AI safety practices.</lvar>\n",
    "<lvar Report.confidence c>0.9</lvar>\n",
    "\n",
    "OUT{report:[t, s, c]}\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    result = parse_lndl(lndl_simple, report_operable)\n",
    "    print(\"Parsed result:\")\n",
    "    print(f\"  Type: {type(result)}\")\n",
    "    print(f\"  Fields: {result.model_fields.keys() if hasattr(result, 'model_fields') else result}\")\n",
    "    if hasattr(result, \"report\"):\n",
    "        print(f\"\\n  report.title: {result.report.title}\")\n",
    "        print(f\"  report.summary: {result.report.summary[:50]}...\")\n",
    "        print(f\"  report.confidence: {result.report.confidence}\")\n",
    "except Exception as e:\n",
    "    print(f\"Parse error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fuzzy LNDL Parsing\n",
    "\n",
    "For LLM outputs that may have minor syntax issues, use fuzzy parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuzzy parsing handles imperfect LLM output\n",
    "messy_lndl = \"\"\"\n",
    "Here's my analysis:\n",
    "\n",
    "<lvar Report.title t>Safety Analysis</lvar>\n",
    "<lvar Report.summary s>The analysis shows significant progress in AI safety.</lvar>\n",
    "\n",
    "OUT{report:[t, s]}\n",
    "\"\"\"\n",
    "\n",
    "# Fuzzy parse with threshold (0.0-1.0)\n",
    "fuzzy_result = parse_lndl_fuzzy(messy_lndl, report_operable, threshold=0.7)\n",
    "\n",
    "print(\"Fuzzy parse result:\")\n",
    "print(f\"  Success: {fuzzy_result.success}\")\n",
    "print(f\"  Confidence: {fuzzy_result.confidence:.2f}\")\n",
    "if fuzzy_result.data:\n",
    "    print(f\"  Data type: {type(fuzzy_result.data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Using LNDL with lionpride Operations\n",
    "\n",
    "The `communicate` and `operate` functions support LNDL via the `operable` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This example requires API keys and won't run without them\n",
    "# It demonstrates the correct API usage pattern\n",
    "\n",
    "\n",
    "# Setup (requires OPENAI_API_KEY or similar)\n",
    "# session = Session()\n",
    "# model = iModel(provider=\"openai\", model=\"gpt-4o-mini\")\n",
    "# session.services.register(model)\n",
    "# branch = session.create_branch(name=\"analysis\")\n",
    "\n",
    "print(\"API Pattern for LNDL with communicate():\")\n",
    "print(\"\"\"\n",
    "# Using LNDL mode via operable parameter\n",
    "result = await communicate(\n",
    "    session=session,\n",
    "    branch=branch,\n",
    "    parameters=CommunicateParam(\n",
    "        instruction=\"Analyze the current state of AI safety research\",\n",
    "        imodel=model.name,\n",
    "        operable=report_operable,  # Enables LNDL mode\n",
    "        return_as=\"model\",\n",
    "        lndl_threshold=0.7,  # Fuzzy matching threshold\n",
    "    )\n",
    ")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"API Pattern for LNDL with operate():\")\n",
    "print(\"\"\"\n",
    "# Using operate with LNDL mode\n",
    "result = await operate(\n",
    "    session=session,\n",
    "    branch=branch,\n",
    "    parameters=OperateParam(\n",
    "        instruction=\"Analyze AI safety and provide reasoning\",\n",
    "        imodel=model.name,\n",
    "        operable=report_operable,  # LNDL structured output\n",
    "        use_lndl=True,\n",
    "        reason=True,  # Add reasoning field\n",
    "        actions=False,  # No tool calling in this example\n",
    "    )\n",
    ")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ReAct Pattern - Multi-Step Tool Calling\n",
    "\n",
    "The `react` operation implements the ReAct (Reasoning + Acting) pattern for multi-step tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lionpride.services.types import Tool\n",
    "\n",
    "\n",
    "# Define a tool\n",
    "def search_documents(query: str, limit: int = 10) -> list[dict]:\n",
    "    \"\"\"Search for documents matching the query.\n",
    "\n",
    "    Args:\n",
    "        query: Search query string\n",
    "        limit: Maximum results to return\n",
    "    \"\"\"\n",
    "    # Mock implementation\n",
    "    return [\n",
    "        {\"title\": f\"Result {i}\", \"snippet\": f\"Content for {query}\"} for i in range(min(limit, 3))\n",
    "    ]\n",
    "\n",
    "\n",
    "# Create Tool instance\n",
    "search_tool = Tool(func_callable=search_documents)\n",
    "\n",
    "print(f\"Tool: {search_tool.name}\")\n",
    "print(f\"Schema: {search_tool.tool_schema}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"API Pattern for react():\")\n",
    "print(\"\"\"\n",
    "# ReAct loop with tool calling\n",
    "result = await react(\n",
    "    session=session,\n",
    "    branch=branch,\n",
    "    parameters=ReactParam(\n",
    "        instruction=\"Find information about AI safety best practices\",\n",
    "        imodel=model.name,\n",
    "        model_name=model.name,\n",
    "        tools=[search_tool],  # Available tools\n",
    "        max_steps=5,  # Maximum reasoning steps\n",
    "        response_model=Report,  # Final answer structure\n",
    "        use_lndl=True,\n",
    "        verbose=True,  # Show step-by-step execution\n",
    "    )\n",
    ")\n",
    "\n",
    "# Result contains:\n",
    "# - result.steps: List of ReactStep with reasoning, actions, observations\n",
    "# - result.final_response: Validated final answer\n",
    "# - result.completed: Whether task completed successfully\n",
    "# - result.total_steps: Number of steps taken\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. LNDL v2 Cognitive Extensions\n",
    "\n",
    "LNDL v2 adds cognitive programming features for advanced workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LNDL v2 Cognitive Extensions:\")\n",
    "print(\"\"\"\n",
    "1. CONTEXT MANAGEMENT\n",
    "   <context>\n",
    "     <include msg=\"msg_id\"/>           # Include specific message\n",
    "     <compress msgs=\"0..50\" to=\"ctx\"/> # Compress messages to symbol\n",
    "     <drop msg=\"verbose_output\"/>      # Drop from context\n",
    "     <notice msg=\"tools\" brief=\"...\"/> # Brief notice\n",
    "   </context>\n",
    "\n",
    "2. CONTINUATION CONTROL\n",
    "   <yield for=\"action\" reason=\"need results\" keep=\"top_5\" drop_full=\"true\"/>\n",
    "   \n",
    "   - Pause execution to wait for action results\n",
    "   - Transform observations (keep, drop_full, transform)\n",
    "   - Resume with observation injected\n",
    "\n",
    "3. MULTI-AGENT COMMUNICATION\n",
    "   <send to=\"critic\" type=\"ReviewRequest\" timeout=\"30s\">\n",
    "     <include msg=\"analysis\"/>\n",
    "   </send>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example LNDL v2 response with yield\n",
    "lndl_v2_example = \"\"\"\n",
    "I need to search for data first.\n",
    "\n",
    "<lact search>search(query=\"AI safety\", limit=10)</lact>\n",
    "\n",
    "<yield for=\"search\" reason=\"need search results\" keep=\"top_3\"/>\n",
    "\n",
    "Based on the results, here's my analysis:\n",
    "<lvar Report.title t>AI Safety Analysis</lvar>\n",
    "<lvar Report.summary s>The search results show...</lvar>\n",
    "\n",
    "OUT{report:[t, s]}\n",
    "\"\"\"\n",
    "\n",
    "# Parse v2 LNDL\n",
    "lexer = Lexer(lndl_v2_example)\n",
    "parser = Parser(lexer.tokenize(), source_text=lndl_v2_example)\n",
    "program = parser.parse()\n",
    "\n",
    "print(\"LNDL v2 Program:\")\n",
    "print(f\"  Yields: {len(program.yields) if program.yields else 0}\")\n",
    "if program.yields:\n",
    "    for y in program.yields:\n",
    "        print(f\"    - for: {y.for_ref}, reason: {y.reason}, keep: {y.keep}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Cognitive React - Full Cognitive Loop\n",
    "\n",
    "The `cognitive_react` function implements the full LNDL v2 cognitive loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"API Pattern for cognitive_react():\")\n",
    "print(\"\"\"\n",
    "# Define permissions for cognitive operations\n",
    "permissions = CognitivePermission(\n",
    "    can_include=True,   # Can include specific messages\n",
    "    can_compress=True,  # Can request message compression\n",
    "    can_drop=True,      # Can request message dropping\n",
    "    can_yield=True,     # Can yield for continuation\n",
    "    max_yields=10,      # Maximum yields per session\n",
    "    can_send=False,     # Multi-agent (disabled)\n",
    ")\n",
    "\n",
    "# Action executor for tool calls\n",
    "async def execute_action(name, call, observations):\n",
    "    # Execute the action and return result\n",
    "    if name == \"search\":\n",
    "        return {\"results\": [\"result1\", \"result2\"]}\n",
    "    return None\n",
    "\n",
    "# Run cognitive react loop\n",
    "result = await cognitive_react(\n",
    "    session=session,\n",
    "    branch=branch,\n",
    "    instruction=\"Research AI safety and provide a comprehensive report\",\n",
    "    imodel=model.name,\n",
    "    action_executor=execute_action,\n",
    "    permissions=permissions,\n",
    "    max_iterations=5,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Result structure:\n",
    "# - result.phases: List of execution phases\n",
    "# - result.final_output: Parsed OUT{} block data\n",
    "# - result.observations: Accumulated action results\n",
    "# - result.completed: Whether completed successfully\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. TypeScript Schema for Input Efficiency\n",
    "\n",
    "lionpride uses TypeScript notation for compact schema representation in prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from lionpride.libs.schema_handlers import typescript_schema\n",
    "\n",
    "# Get JSON Schema from Pydantic model\n",
    "json_schema = Report.model_json_schema()\n",
    "\n",
    "# Convert to TypeScript notation\n",
    "ts_schema = typescript_schema(json_schema)\n",
    "\n",
    "print(\"JSON Schema (verbose):\")\n",
    "print(json.dumps(json_schema, indent=2))\n",
    "print(f\"\\nJSON Schema tokens: ~{len(json.dumps(json_schema)) // 4}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"\\nTypeScript Schema (compact):\")\n",
    "print(ts_schema)\n",
    "print(f\"\\nTypeScript tokens: ~{len(ts_schema) // 4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex model example\n",
    "class Employment(BaseModel):\n",
    "    company: str\n",
    "    position: str\n",
    "    start_date: str\n",
    "    end_date: str | None = None\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    email: str\n",
    "    current_job: Employment\n",
    "    previous_jobs: list[Employment] = []\n",
    "    skills: list[str] = []\n",
    "    is_active: bool = True\n",
    "\n",
    "\n",
    "json_schema = Person.model_json_schema()\n",
    "ts_schema = typescript_schema(json_schema)\n",
    "\n",
    "print(\"Complex Model - TypeScript Schema:\")\n",
    "print(ts_schema)\n",
    "print(f\"\\nJSON: ~{len(json.dumps(json_schema)) // 4} tokens\")\n",
    "print(f\"TypeScript: ~{len(ts_schema) // 4} tokens\")\n",
    "print(f\"Reduction: ~{(1 - len(ts_schema) / len(json.dumps(json_schema))) * 100:.0f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### LNDL Syntax\n",
    "- **Variables**: `<lvar Model.field alias>value</lvar>` - explicit field mapping\n",
    "- **Actions**: `<lact name>function(args)</lact>` - lazy execution\n",
    "- **Output**: `OUT{field:[vars], scalar:literal}` - final structure\n",
    "\n",
    "### Key Features\n",
    "- **Natural thinking**: Prose + declarations intermixed\n",
    "- **Lazy execution**: Only OUT{}-referenced actions run\n",
    "- **Multiple versions**: Explore options, select final in OUT{}\n",
    "- **Fuzzy parsing**: Tolerates minor LLM syntax errors\n",
    "\n",
    "### Integration Points\n",
    "- `communicate(operable=...)` - LNDL mode for structured chat\n",
    "- `operate(use_lndl=True)` - LNDL with reasoning/actions\n",
    "- `react(...)` - Multi-step ReAct loops\n",
    "- `cognitive_react(...)` - Full LNDL v2 cognitive programming\n",
    "\n",
    "### LNDL v2 Extensions\n",
    "- Context management (`<context>`, `<compress>`, `<drop>`)\n",
    "- Continuation control (`<yield>` for action results)\n",
    "- Multi-agent communication (`<send>` to other agents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
