{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool Calling: Building Agentic Workflows\n",
    "\n",
    "This notebook demonstrates how to build agentic workflows using lionpride's **ReAct** (Reasoning + Acting) pattern. You'll learn how to:\n",
    "\n",
    "- Define tools that LLMs can use\n",
    "- Use `react()` for multi-step reasoning loops\n",
    "- Build practical agents with real-world tools\n",
    "- Handle errors and structured outputs\n",
    "\n",
    "**What you'll build**: Calculator assistant, research agent, data analyst, and weather advisor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Tool Calling?\n",
    "\n",
    "**Tool calling** enables LLMs to interact with external functions, APIs, and systems. Instead of just generating text, the LLM can:\n",
    "\n",
    "1. **Reason** about what action to take\n",
    "2. **Act** by calling a tool with arguments\n",
    "3. **Observe** the tool's result\n",
    "4. **Repeat** until it has enough information to answer\n",
    "\n",
    "This is the **ReAct pattern** (Reason + Act):\n",
    "\n",
    "```\n",
    "Instruction ‚Üí Reasoning ‚Üí Tool Call ‚Üí Observation ‚Üí Reasoning ‚Üí ... ‚Üí Final Answer\n",
    "```\n",
    "\n",
    "**lionpride's `react()`** operation implements this loop with:\n",
    "- Automatic tool schema generation\n",
    "- Multi-step reasoning control (`max_steps`)\n",
    "- Structured output support\n",
    "- Error handling and retries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (uncomment if needed)\n",
    "# !pip install lionpride pydantic python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Load API keys from environment\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from lionpride import Session\n",
    "from lionpride.operations import react\n",
    "from lionpride.services import Tool, iModel\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "print(\"‚úÖ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Calculator Assistant\n",
    "\n",
    "Let's build a simple math assistant that can add and multiply numbers. The LLM will break down complex calculations into tool calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define calculator tools\n",
    "# Note: Tool names must be at least 4 characters\n",
    "def add_nums(a: float, b: float) -> float:\n",
    "    \"\"\"Add two numbers together\"\"\"\n",
    "    result = a + b\n",
    "    print(f\"  add_nums({a}, {b}) = {result}\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def multiply_nums(a: float, b: float) -> float:\n",
    "    \"\"\"Multiply two numbers together\"\"\"\n",
    "    result = a * b\n",
    "    print(f\"  multiply_nums({a}, {b}) = {result}\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def subtract_nums(a: float, b: float) -> float:\n",
    "    \"\"\"Subtract b from a\"\"\"\n",
    "    result = a - b\n",
    "    print(f\"  subtract_nums({a}, {b}) = {result}\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def divide_nums(a: float, b: float) -> float:\n",
    "    \"\"\"Divide a by b\"\"\"\n",
    "    if b == 0:\n",
    "        raise ValueError(\"Cannot divide by zero!\")\n",
    "    result = a / b\n",
    "    print(f\"  divide_nums({a}, {b}) = {result}\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def calculator_agent():\n",
    "    \"\"\"Math assistant using calculator tools\"\"\"\n",
    "    # Create session and model\n",
    "    session = Session()\n",
    "    model = iModel(provider=\"openai\", model=\"gpt-4o-mini\", temperature=0)\n",
    "    session.services.register(model)\n",
    "\n",
    "    # Create tools from functions using Tool(func_callable=)\n",
    "    add_tool = Tool(func_callable=add_nums)\n",
    "    multiply_tool = Tool(func_callable=multiply_nums)\n",
    "    subtract_tool = Tool(func_callable=subtract_nums)\n",
    "    divide_tool = Tool(func_callable=divide_nums)\n",
    "\n",
    "    # Note: Tools are automatically registered by react() - no need to register manually\n",
    "\n",
    "    # Create branch for conversation\n",
    "    branch = session.create_branch(name=\"calculator\")\n",
    "\n",
    "    # Run ReAct loop\n",
    "    print(\"Question: What is (15 + 27) * 3 - 10?\\n\")\n",
    "\n",
    "    result = await react(\n",
    "        session=session,\n",
    "        branch=branch,\n",
    "        parameters={\n",
    "            \"instruction\": \"What is (15 + 27) * 3 - 10?\",\n",
    "            \"imodel\": model.name,\n",
    "            \"model_name\": model.name,  # Required for tool schema generation\n",
    "            \"tools\": [add_tool, multiply_tool, subtract_tool, divide_tool],  # Pass Tool instances\n",
    "            \"max_steps\": 5,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    print(f\"\\nFinal Answer: {result.final_response}\")\n",
    "    print(f\"Steps taken: {result.total_steps}\")\n",
    "    print(f\"Completed: {result.completed}\")\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# Run the calculator agent\n",
    "result = await calculator_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the ReAct Trace\n",
    "\n",
    "Let's examine how the LLM reasoned through the problem step-by-step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìã Detailed Reasoning Trace:\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for step in result.steps:\n",
    "    print(f\"\\nüîÑ Step {step.step}:\")\n",
    "    print(f\"   Reasoning: {step.reasoning[:150]}...\")  # Truncate for readability\n",
    "\n",
    "    if step.actions_requested:\n",
    "        for action in step.actions_requested:\n",
    "            print(f\"   üõ†Ô∏è  Tool: {action.function}\")\n",
    "            print(f\"   üì• Args: {action.arguments}\")\n",
    "\n",
    "    if step.actions_executed:\n",
    "        for action in step.actions_executed:\n",
    "            print(f\"   üì§ Result: {action.output}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Research Agent with Web Search\n",
    "\n",
    "Build an agent that can search the web and retrieve current information. We'll simulate a search API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define research tools\n",
    "def search_web(query: str, num_results: int = 3) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Search the web for information.\n",
    "\n",
    "    Args:\n",
    "        query: Search query string\n",
    "        num_results: Number of results to return (1-5)\n",
    "\n",
    "    Returns:\n",
    "        List of search results with title, snippet, and url\n",
    "    \"\"\"\n",
    "    print(f\"  üîç Searching web for: '{query}'\")\n",
    "\n",
    "    # Simulated search results based on query\n",
    "    if \"AI\" in query or \"artificial intelligence\" in query.lower():\n",
    "        results = [\n",
    "            {\n",
    "                \"title\": \"OpenAI Announces GPT-5 Development\",\n",
    "                \"snippet\": \"OpenAI confirms work on next-generation language model with enhanced reasoning capabilities...\",\n",
    "                \"url\": \"https://openai.com/news/gpt5\",\n",
    "            },\n",
    "            {\n",
    "                \"title\": \"DeepMind's AlphaFold 3 Breakthrough\",\n",
    "                \"snippet\": \"New protein folding predictions achieve unprecedented accuracy for drug discovery...\",\n",
    "                \"url\": \"https://deepmind.com/alphafold3\",\n",
    "            },\n",
    "            {\n",
    "                \"title\": \"EU AI Act Becomes Law\",\n",
    "                \"snippet\": \"European Union implements comprehensive AI regulation framework...\",\n",
    "                \"url\": \"https://ec.europa.eu/ai-act\",\n",
    "            },\n",
    "        ]\n",
    "    elif \"Python\" in query:\n",
    "        results = [\n",
    "            {\n",
    "                \"title\": \"Python 3.13 Released\",\n",
    "                \"snippet\": \"Latest Python version features performance improvements and new syntax...\",\n",
    "                \"url\": \"https://python.org/3.13\",\n",
    "            },\n",
    "            {\n",
    "                \"title\": \"FastAPI 0.110 Update\",\n",
    "                \"snippet\": \"Modern web framework adds native async support...\",\n",
    "                \"url\": \"https://fastapi.tiangolo.com\",\n",
    "            },\n",
    "        ]\n",
    "    else:\n",
    "        results = [\n",
    "            {\n",
    "                \"title\": f\"Result {i + 1} for '{query}'\",\n",
    "                \"snippet\": f\"This is information about {query}...\",\n",
    "                \"url\": f\"https://example.com/result{i + 1}\",\n",
    "            }\n",
    "            for i in range(num_results)\n",
    "        ]\n",
    "\n",
    "    return results[:num_results]\n",
    "\n",
    "\n",
    "def get_current_date() -> str:\n",
    "    \"\"\"Get the current date in YYYY-MM-DD format\"\"\"\n",
    "    date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    print(f\"  üìÖ Current date: {date}\")\n",
    "    return date\n",
    "\n",
    "\n",
    "def get_current_time() -> str:\n",
    "    \"\"\"Get the current time in HH:MM:SS format\"\"\"\n",
    "    time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(f\"  üïê Current time: {time}\")\n",
    "    return time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def research_agent():\n",
    "    \"\"\"Research assistant using search tools\"\"\"\n",
    "    session = Session()\n",
    "    model = iModel(\n",
    "        provider=\"anthropic\", endpoint=\"messages\", model=\"claude-3-5-sonnet-20241022\", temperature=0\n",
    "    )\n",
    "    session.services.register(model)\n",
    "\n",
    "    # Create tools using Tool(func_callable=)\n",
    "    search_tool = Tool(func_callable=search_web)\n",
    "    date_tool = Tool(func_callable=get_current_date)\n",
    "    time_tool = Tool(func_callable=get_current_time)\n",
    "\n",
    "    # Note: Tools are automatically registered by react() - no need to register manually\n",
    "\n",
    "    branch = session.create_branch(name=\"research\")\n",
    "\n",
    "    print(\"ü§î Question: What are the major AI breakthroughs this year?\\n\")\n",
    "\n",
    "    result = await react(\n",
    "        session=session,\n",
    "        branch=branch,\n",
    "        parameters={\n",
    "            \"instruction\": \"What are the major AI breakthroughs this year? Give me 3 key developments.\",\n",
    "            \"imodel\": model.name,\n",
    "            \"model_name\": model.name,  # Required for tool schema generation\n",
    "            \"tools\": [search_tool, date_tool, time_tool],  # Pass Tool instances\n",
    "            \"max_steps\": 5,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    print(f\"\\nüìù Research Result:\\n{result.final_response}\")\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# Run research agent\n",
    "result = await research_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Data Analyst Agent\n",
    "\n",
    "Build an agent that queries a database and performs calculations. This demonstrates multi-step reasoning with data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated employee database\n",
    "DATABASE = {\n",
    "    \"employees\": [\n",
    "        {\"id\": 1, \"name\": \"Alice Chen\", \"department\": \"Engineering\", \"salary\": 120000, \"years\": 5},\n",
    "        {\"id\": 2, \"name\": \"Bob Smith\", \"department\": \"Sales\", \"salary\": 90000, \"years\": 3},\n",
    "        {\"id\": 3, \"name\": \"Charlie Kim\", \"department\": \"Engineering\", \"salary\": 110000, \"years\": 4},\n",
    "        {\"id\": 4, \"name\": \"Diana Lopez\", \"department\": \"Sales\", \"salary\": 95000, \"years\": 2},\n",
    "        {\"id\": 5, \"name\": \"Eve Johnson\", \"department\": \"Engineering\", \"salary\": 130000, \"years\": 7},\n",
    "        {\"id\": 6, \"name\": \"Frank Wilson\", \"department\": \"Marketing\", \"salary\": 85000, \"years\": 3},\n",
    "    ],\n",
    "    \"projects\": [\n",
    "        {\"id\": 1, \"name\": \"AI Platform\", \"budget\": 500000, \"team\": \"Engineering\"},\n",
    "        {\"id\": 2, \"name\": \"Sales Campaign\", \"budget\": 200000, \"team\": \"Sales\"},\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "def query_database(table: str, filter_by: str | None = None) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Query a database table with optional filtering.\n",
    "\n",
    "    Args:\n",
    "        table: Table name (e.g., 'employees', 'projects')\n",
    "        filter_by: Optional filter like 'department=Engineering' or 'years>3'\n",
    "\n",
    "    Returns:\n",
    "        List of matching records\n",
    "    \"\"\"\n",
    "    print(f\"  üíæ Querying table: {table} (filter: {filter_by or 'none'})\")\n",
    "\n",
    "    data = DATABASE.get(table, [])\n",
    "\n",
    "    if filter_by:\n",
    "        # Parse simple filters like \"key=value\" or \"key>value\"\n",
    "        if \"=\" in filter_by:\n",
    "            key, value = filter_by.split(\"=\")\n",
    "            data = [row for row in data if str(row.get(key)) == value]\n",
    "        elif \">\" in filter_by:\n",
    "            key, value = filter_by.split(\">\")\n",
    "            data = [row for row in data if row.get(key, 0) > int(value)]\n",
    "        elif \"<\" in filter_by:\n",
    "            key, value = filter_by.split(\"<\")\n",
    "            data = [row for row in data if row.get(key, 0) < int(value)]\n",
    "\n",
    "    print(f\"  üìä Found {len(data)} records\")\n",
    "    return data\n",
    "\n",
    "\n",
    "def calculate_average(numbers: list[float]) -> float:\n",
    "    \"\"\"Calculate the average of a list of numbers\"\"\"\n",
    "    if not numbers:\n",
    "        return 0.0\n",
    "    avg = sum(numbers) / len(numbers)\n",
    "    print(f\"  üìà Average of {len(numbers)} values: {avg:,.2f}\")\n",
    "    return avg\n",
    "\n",
    "\n",
    "def calculate_sum(numbers: list[float]) -> float:\n",
    "    \"\"\"Calculate the sum of a list of numbers\"\"\"\n",
    "    total = sum(numbers)\n",
    "    print(f\"  ‚ûï Sum of {len(numbers)} values: {total:,.2f}\")\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def data_analyst_agent():\n",
    "    \"\"\"Data analyst using database query tools\"\"\"\n",
    "    session = Session()\n",
    "    model = iModel(provider=\"openai\", model=\"gpt-4o\", temperature=0)\n",
    "    session.services.register(model)\n",
    "\n",
    "    # Create data analysis tools using Tool(func_callable=)\n",
    "    query_tool = Tool(func_callable=query_database)\n",
    "    avg_tool = Tool(func_callable=calculate_average)\n",
    "    sum_tool = Tool(func_callable=calculate_sum)\n",
    "\n",
    "    # Note: Tools are automatically registered by react() - no need to register manually\n",
    "\n",
    "    branch = session.create_branch(name=\"analysis\")\n",
    "\n",
    "    print(\n",
    "        \"ü§î Question: What is the average salary of employees in Engineering with more than 4 years of experience?\\n\"\n",
    "    )\n",
    "\n",
    "    result = await react(\n",
    "        session=session,\n",
    "        branch=branch,\n",
    "        parameters={\n",
    "            \"instruction\": (\n",
    "                \"What is the average salary of employees in the Engineering department \"\n",
    "                \"who have more than 4 years of experience?\"\n",
    "            ),\n",
    "            \"imodel\": model.name,\n",
    "            \"model_name\": model.name,  # Required for tool schema generation\n",
    "            \"tools\": [query_tool, avg_tool, sum_tool],  # Pass Tool instances\n",
    "            \"max_steps\": 5,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    print(f\"\\nüíº Analysis Result: {result.final_response}\")\n",
    "\n",
    "    # Show tool execution trace\n",
    "    print(\"\\nüîç Tool Execution Trace:\")\n",
    "    for step in result.steps:\n",
    "        if step.actions_executed:\n",
    "            for action in step.actions_executed:\n",
    "                print(f\"   {action.function}({action.arguments}) ‚Üí {action.output}\")\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# Run data analyst agent\n",
    "result = await data_analyst_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Error Handling in Tools\n",
    "\n",
    "See how the ReAct loop handles tool errors gracefully. The LLM observes the error and can retry with corrected arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Tool names must be at least 4 characters\n",
    "def safe_divide(a: float, b: float) -> float:\n",
    "    \"\"\"Divide a by b with error handling\"\"\"\n",
    "    if b == 0:\n",
    "        print(\"  Error: Cannot divide by zero!\")\n",
    "        raise ValueError(\"Division by zero is not allowed\")\n",
    "    result = a / b\n",
    "    print(f\"  safe_divide({a}, {b}) = {result}\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_number_info(n: int) -> dict:\n",
    "    \"\"\"Get information about a number\"\"\"\n",
    "    if n < 0:\n",
    "        print(\"  Error: Negative numbers not supported!\")\n",
    "        raise ValueError(\"Number must be non-negative\")\n",
    "\n",
    "    info = {\n",
    "        \"number\": n,\n",
    "        \"is_even\": n % 2 == 0,\n",
    "        \"is_prime\": n > 1 and all(n % i != 0 for i in range(2, int(n**0.5) + 1)),\n",
    "        \"square\": n**2,\n",
    "    }\n",
    "    print(f\"  Info for {n}: even={info['is_even']}, prime={info['is_prime']}\")\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def error_handling_demo():\n",
    "    \"\"\"Demonstrate error handling in ReAct loop\"\"\"\n",
    "    session = Session()\n",
    "    model = iModel(provider=\"openai\", model=\"gpt-4o-mini\", temperature=0)\n",
    "    session.services.register(model)\n",
    "\n",
    "    # Create tools using Tool(func_callable=)\n",
    "    divide_tool = Tool(func_callable=safe_divide)\n",
    "    info_tool = Tool(func_callable=get_number_info)\n",
    "\n",
    "    # Note: Tools are automatically registered by react() - no need to register manually\n",
    "\n",
    "    branch = session.create_branch(name=\"error_demo\")\n",
    "\n",
    "    print(\"ü§î Question: Divide 100 by (5 - 5) and tell me about the result\\n\")\n",
    "    print(\"(This will trigger a division by zero error, then recover)\\n\")\n",
    "\n",
    "    result = await react(\n",
    "        session=session,\n",
    "        branch=branch,\n",
    "        parameters={\n",
    "            \"instruction\": (\n",
    "                \"First divide 100 by (5 - 5), then give me information about the result.\"\n",
    "            ),\n",
    "            \"imodel\": model.name,\n",
    "            \"model_name\": model.name,  # Required for tool schema generation\n",
    "            \"tools\": [divide_tool, info_tool],  # Pass Tool instances\n",
    "            \"max_steps\": 5,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    print(f\"\\nüéØ Result: {result.final_response}\")\n",
    "    print(\"\\nüìù Note: The LLM observed the error and corrected its approach\")\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# Run error handling demo\n",
    "result = await error_handling_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Structured Output with Tool Calling\n",
    "\n",
    "Combine tool calling with structured outputs using Pydantic models. The LLM gathers information via tools, then returns a typed response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define structured output model\n",
    "class WeatherReport(BaseModel):\n",
    "    \"\"\"Complete weather report with recommendations\"\"\"\n",
    "\n",
    "    city: str = Field(..., description=\"City name\")\n",
    "    temperature: float = Field(..., description=\"Temperature in Fahrenheit\")\n",
    "    condition: str = Field(..., description=\"Weather condition (e.g., Sunny, Rainy)\")\n",
    "    humidity: int = Field(..., description=\"Humidity percentage\")\n",
    "    recommendation: str = Field(..., description=\"What to wear and bring\")\n",
    "\n",
    "\n",
    "def get_weather(city: str) -> dict:\n",
    "    \"\"\"Get current weather for a city\"\"\"\n",
    "    print(f\"  üå§Ô∏è  Fetching weather for: {city}\")\n",
    "\n",
    "    # Simulated weather API\n",
    "    weather_data = {\n",
    "        \"San Francisco\": {\"temp\": 65, \"condition\": \"Foggy\", \"humidity\": 75},\n",
    "        \"New York\": {\"temp\": 78, \"condition\": \"Sunny\", \"humidity\": 60},\n",
    "        \"Seattle\": {\"temp\": 55, \"condition\": \"Rainy\", \"humidity\": 85},\n",
    "        \"Miami\": {\"temp\": 88, \"condition\": \"Humid\", \"humidity\": 80},\n",
    "        \"Chicago\": {\"temp\": 70, \"condition\": \"Cloudy\", \"humidity\": 65},\n",
    "    }\n",
    "\n",
    "    data = weather_data.get(city, {\"temp\": 72, \"condition\": \"Unknown\", \"humidity\": 50})\n",
    "    print(f\"  üìä {data['temp']}¬∞F, {data['condition']}, {data['humidity']}% humidity\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def weather_agent():\n",
    "    \"\"\"Weather advisor with structured output\"\"\"\n",
    "    session = Session()\n",
    "    model = iModel(provider=\"openai\", model=\"gpt-4o\", temperature=0)\n",
    "    session.services.register(model)\n",
    "\n",
    "    # Create tool using Tool(func_callable=)\n",
    "    weather_tool = Tool(func_callable=get_weather)\n",
    "\n",
    "    # Note: Tools are automatically registered by react() - no need to register manually\n",
    "\n",
    "    branch = session.create_branch(name=\"weather\")\n",
    "\n",
    "    print(\"ü§î Question: What's the weather in Seattle and what should I wear?\\n\")\n",
    "\n",
    "    result = await react(\n",
    "        session=session,\n",
    "        branch=branch,\n",
    "        parameters={\n",
    "            \"instruction\": \"What's the weather in Seattle and what should I wear?\",\n",
    "            \"imodel\": model.name,\n",
    "            \"model_name\": model.name,  # Required for tool schema generation\n",
    "            \"tools\": [weather_tool],  # Pass Tool instances\n",
    "            \"response_model\": WeatherReport,  # Request structured output\n",
    "            \"max_steps\": 3,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Parse structured response\n",
    "    weather: WeatherReport = result.final_response\n",
    "\n",
    "    print(\"\\nüå¶Ô∏è  Weather Report:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"üìç City: {weather.city}\")\n",
    "    print(f\"üå°Ô∏è  Temperature: {weather.temperature}¬∞F\")\n",
    "    print(f\"‚òÅÔ∏è  Condition: {weather.condition}\")\n",
    "    print(f\"üíß Humidity: {weather.humidity}%\")\n",
    "    print(f\"\\nüëï Recommendation: {weather.recommendation}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# Run weather agent\n",
    "result = await weather_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 6: Parallel Tool Calling\n",
    "\n",
    "Some models (like GPT-4) support calling multiple tools in parallel within a single step. This is useful for independent operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stock market tools\n",
    "def get_stock_price(symbol: str) -> float:\n",
    "    \"\"\"Get current stock price for a symbol\"\"\"\n",
    "    prices = {\n",
    "        \"AAPL\": 178.50,\n",
    "        \"GOOGL\": 142.30,\n",
    "        \"MSFT\": 380.20,\n",
    "        \"AMZN\": 155.60,\n",
    "        \"TSLA\": 248.80,\n",
    "    }\n",
    "    price = prices.get(symbol.upper(), 0.0)\n",
    "    print(f\"  üí∞ {symbol}: ${price}\")\n",
    "    return price\n",
    "\n",
    "\n",
    "def get_company_info(symbol: str) -> dict:\n",
    "    \"\"\"Get company information for a stock symbol\"\"\"\n",
    "    info = {\n",
    "        \"AAPL\": {\"name\": \"Apple Inc.\", \"sector\": \"Technology\", \"founded\": 1976},\n",
    "        \"GOOGL\": {\"name\": \"Alphabet Inc.\", \"sector\": \"Technology\", \"founded\": 1998},\n",
    "        \"MSFT\": {\"name\": \"Microsoft Corp.\", \"sector\": \"Technology\", \"founded\": 1975},\n",
    "        \"AMZN\": {\"name\": \"Amazon.com Inc.\", \"sector\": \"E-Commerce\", \"founded\": 1994},\n",
    "        \"TSLA\": {\"name\": \"Tesla Inc.\", \"sector\": \"Automotive\", \"founded\": 2003},\n",
    "    }\n",
    "    company = info.get(symbol.upper(), {})\n",
    "    print(f\"  üè¢ {symbol}: {company.get('name', 'Unknown')}\")\n",
    "    return company\n",
    "\n",
    "\n",
    "def calculate_market_cap(price: float, shares_outstanding: int) -> float:\n",
    "    \"\"\"Calculate market capitalization\"\"\"\n",
    "    market_cap = price * shares_outstanding\n",
    "    print(f\"  üìä Market cap: ${market_cap:,.0f}\")\n",
    "    return market_cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def stock_analyzer():\n",
    "    \"\"\"Stock analysis with parallel tool calls\"\"\"\n",
    "    session = Session()\n",
    "    model = iModel(\n",
    "        provider=\"openai\",\n",
    "        model=\"gpt-4o\",  # GPT-4 supports parallel tool calling\n",
    "        temperature=0,\n",
    "    )\n",
    "    session.services.register(model)\n",
    "\n",
    "    # Create tools using Tool(func_callable=)\n",
    "    price_tool = Tool(func_callable=get_stock_price)\n",
    "    info_tool = Tool(func_callable=get_company_info)\n",
    "    cap_tool = Tool(func_callable=calculate_market_cap)\n",
    "\n",
    "    # Note: Tools are automatically registered by react() - no need to register manually\n",
    "\n",
    "    branch = session.create_branch(name=\"stocks\")\n",
    "\n",
    "    print(\"ü§î Question: Compare Apple (AAPL) and Microsoft (MSFT) stocks\\n\")\n",
    "\n",
    "    result = await react(\n",
    "        session=session,\n",
    "        branch=branch,\n",
    "        parameters={\n",
    "            \"instruction\": (\n",
    "                \"Compare Apple (AAPL) and Microsoft (MSFT) stocks. \"\n",
    "                \"Give me prices and company information for both.\"\n",
    "            ),\n",
    "            \"imodel\": model.name,\n",
    "            \"model_name\": model.name,  # Required for tool schema generation\n",
    "            \"tools\": [price_tool, info_tool, cap_tool],  # Pass Tool instances\n",
    "            \"max_steps\": 3,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    print(f\"\\nüìà Stock Analysis:\\n{result.final_response}\")\n",
    "\n",
    "    # Check if tools were called in parallel\n",
    "    print(\"\\nüîç Checking for parallel tool execution:\")\n",
    "    for step in result.steps:\n",
    "        if step.actions_requested and len(step.actions_requested) > 1:\n",
    "            print(f\"  ‚úÖ Step {step.step}: {len(step.actions_requested)} tools called in parallel!\")\n",
    "            for action in step.actions_requested:\n",
    "                print(f\"     - {action.function}({action.arguments})\")\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# Run stock analyzer\n",
    "result = await stock_analyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Key Takeaways\n\n### 1. Tool Definition\n```python\n# From function using Tool(func_callable=)\ntool = Tool(func_callable=my_function)\n\n# Type hints are critical for schema generation\ndef my_tool(x: float, y: float) -> float:\n    \"\"\"Clear docstring helps LLM understand when to use this tool\"\"\"\n    return x + y\n```\n\n### 2. ReAct Loop Control\n```python\nresult = await react(\n    session=session,\n    branch=branch,\n    parameters={\n        \"max_steps\": 5,           # Limit iterations (prevent infinite loops)\n        \"response_model\": Model,  # Optional structured output\n    }\n)\n```\n\n### 3. Error Handling\n- Tools can raise exceptions\n- LLM observes the error message\n- Can retry with corrected arguments\n- Set reasonable `max_steps` to prevent infinite retries\n\n### 4. Best Practices\n- ‚úÖ Use clear function names and docstrings\n- ‚úÖ Add type hints for all parameters\n- ‚úÖ Register tools before calling `react()`\n- ‚úÖ Set `max_steps` to prevent infinite loops\n- ‚úÖ Make tools focused (single responsibility)\n- ‚ö†Ô∏è Avoid stateful tools (use session state instead)\n- ‚ö†Ô∏è Keep tool execution fast (<5 seconds)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<cell_type>markdown</cell_type>## Common Pitfalls\n\n### ‚ùå Passing tool names instead of Tool instances\n```python\ntool = Tool(func_callable=my_func)\n# WRONG: tools expects Tool instances, not strings\nresult = await react(parameters={\"tools\": [tool.name]})\n\n# CORRECT: Pass Tool instances\nresult = await react(parameters={\"tools\": [tool]})\n```\n\n### ‚ùå Missing model_name parameter\n```python\n# WRONG: model_name is required for tool schema generation\nresult = await react(parameters={\"imodel\": model.name, \"tools\": [tool]})\n\n# CORRECT: Include model_name\nresult = await react(parameters={\n    \"imodel\": model.name,\n    \"model_name\": model.name,  # Required!\n    \"tools\": [tool],\n})\n```\n\n### ‚ùå Missing type hints\n```python\ndef bad_tool(x, y):  # No types = poor schema\n    return x + y\n\n# CORRECT: Always use type hints\ndef good_tool(x: float, y: float) -> float:\n    \"\"\"Add two numbers together.\"\"\"\n    return x + y\n```\n\n### ‚ùå No max_steps (infinite loop risk)\n```python\nresult = await react(...)  # Could loop forever!\n\n# CORRECT: Always set max_steps\nresult = await react(parameters={\"max_steps\": 10})\n```\n\n### ‚úÖ Complete correct pattern\n```python\n# Create tools\ntool1 = Tool(func_callable=my_func1)\ntool2 = Tool(func_callable=my_func2)\n\n# Run react with correct parameters\nresult = await react(\n    session=session,\n    branch=branch,\n    parameters={\n        \"instruction\": \"Do something\",\n        \"imodel\": model.name,\n        \"model_name\": model.name,\n        \"tools\": [tool1, tool2],  # Tool instances, not names\n        \"max_steps\": 10,\n    }\n)\n```"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now that you understand tool calling, explore:\n",
    "\n",
    "1. **Multi-Agent Workflows** - Combine multiple specialized agents\n",
    "2. **Streaming** - Stream tool calls and results in real-time\n",
    "3. **Custom Tools** - Build domain-specific tools for your use case\n",
    "4. **Tool Chaining** - Create complex workflows with dependent tools\n",
    "\n",
    "**Resources**:\n",
    "- [lionpride docs](https://github.com/khive-ai/lionpride)\n",
    "- [Tool API reference](../docs/api/services.md)\n",
    "- [ReAct pattern deep dive](../docs/patterns/react.md)\n",
    "\n",
    "---\n",
    "\n",
    "**You've completed the Tool Calling notebook! üéâ**\n",
    "\n",
    "You now know how to:\n",
    "- Define tools from Python functions\n",
    "- Use `react()` for multi-step reasoning\n",
    "- Handle errors and structured outputs\n",
    "- Build practical agentic workflows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
