{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# ln._utils - Core Utility Functions\n",
    "\n",
    "Essential utilities for lionpride operations:\n",
    "\n",
    "**Time Management:**\n",
    "- **now_utc()**: Current UTC timestamp\n",
    "\n",
    "**Async Path Operations:**\n",
    "- **acreate_path()**: Async file path creation with timestamps, random hashes, and timeouts\n",
    "\n",
    "**Data Organization:**\n",
    "- **get_bins()**: Bin packing for strings by cumulative length\n",
    "\n",
    "**Dynamic Imports:**\n",
    "- **import_module()**: Flexible module importing by path\n",
    "- **is_import_installed()**: Check package availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T18:55:18.642414Z",
     "iopub.status.busy": "2025-11-23T18:55:18.642339Z",
     "iopub.status.idle": "2025-11-23T18:55:18.754574Z",
     "shell.execute_reply": "2025-11-23T18:55:18.754022Z"
    }
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "from lionpride.ln._utils import (\n",
    "    acreate_path,\n",
    "    get_bins,\n",
    "    import_module,\n",
    "    is_import_installed,\n",
    "    now_utc,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. UTC Timestamps with now_utc()\n",
    "\n",
    "Simple utility to get timezone-aware UTC datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T18:55:18.756396Z",
     "iopub.status.busy": "2025-11-23T18:55:18.756294Z",
     "iopub.status.idle": "2025-11-23T18:55:18.758683Z",
     "shell.execute_reply": "2025-11-23T18:55:18.758251Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current UTC: 2025-11-23 18:55:18.756923+00:00\n",
      "Timezone: UTC\n",
      "ISO format: 2025-11-23T18:55:18.756923+00:00\n"
     ]
    }
   ],
   "source": [
    "# Get current UTC time\n",
    "timestamp = now_utc()\n",
    "print(f\"Current UTC: {timestamp}\")\n",
    "print(f\"Timezone: {timestamp.tzinfo}\")\n",
    "print(f\"ISO format: {timestamp.isoformat()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T18:55:18.760056Z",
     "iopub.status.busy": "2025-11-23T18:55:18.759956Z",
     "iopub.status.idle": "2025-11-23T18:55:18.864139Z",
     "shell.execute_reply": "2025-11-23T18:55:18.863651Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0.10s\n",
      "Both have UTC timezone: True\n"
     ]
    }
   ],
   "source": [
    "# Use for consistent timestamps\n",
    "import time\n",
    "\n",
    "t1 = now_utc()\n",
    "time.sleep(0.1)\n",
    "t2 = now_utc()\n",
    "\n",
    "print(f\"Time elapsed: {(t2 - t1).total_seconds():.2f}s\")\n",
    "print(f\"Both have UTC timezone: {t1.tzinfo == t2.tzinfo}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 2. Async Path Creation with acreate_path()\n",
    "\n",
    "Flexible async file path generation with:\n",
    "- Subdirectory support via `/` in filename\n",
    "- Optional timestamps\n",
    "- Random hash suffixes\n",
    "- Timeout protection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T18:55:18.865616Z",
     "iopub.status.busy": "2025-11-23T18:55:18.865527Z",
     "iopub.status.idle": "2025-11-23T18:55:18.870777Z",
     "shell.execute_reply": "2025-11-23T18:55:18.870474Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: /var/folders/5p/rcbw097d29j3s2qt861tsjfh0000gn/T/tmpph29iiqo/test.txt\n",
      "Type: Path\n",
      "Exists: True\n"
     ]
    }
   ],
   "source": [
    "# Basic usage - simple filename\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    path = await acreate_path(tmpdir, \"test\", \"txt\")\n",
    "    print(f\"Created: {path}\")\n",
    "    print(f\"Type: {type(path).__name__}\")\n",
    "    print(f\"Exists: {await path.parent.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T18:55:18.871962Z",
     "iopub.status.busy": "2025-11-23T18:55:18.871894Z",
     "iopub.status.idle": "2025-11-23T18:55:18.875284Z",
     "shell.execute_reply": "2025-11-23T18:55:18.874856Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path: /var/folders/5p/rcbw097d29j3s2qt861tsjfh0000gn/T/tmpspeg0rsv/logs/2025/report.txt\n",
      "Parent exists: True\n",
      "Parent name: 2025\n"
     ]
    }
   ],
   "source": [
    "# Subdirectory support - filename with slashes\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    path = await acreate_path(tmpdir, \"logs/2025/report.txt\")\n",
    "    print(f\"Path: {path}\")\n",
    "    print(f\"Parent exists: {await path.parent.exists()}\")\n",
    "    print(f\"Parent name: {path.parent.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T18:55:18.876338Z",
     "iopub.status.busy": "2025-11-23T18:55:18.876278Z",
     "iopub.status.idle": "2025-11-23T18:55:18.879960Z",
     "shell.execute_reply": "2025-11-23T18:55:18.879563Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suffix: report_20251123135518.txt\n",
      "Prefix: 20251123135518_report.txt\n",
      "Custom format: report_2025-11-23.txt\n"
     ]
    }
   ],
   "source": [
    "# Timestamp options\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    # Timestamp suffix (default)\n",
    "    path1 = await acreate_path(tmpdir, \"report\", \"txt\", timestamp=True)\n",
    "    print(f\"Suffix: {path1.name}\")\n",
    "\n",
    "    # Timestamp prefix\n",
    "    path2 = await acreate_path(tmpdir, \"report\", \"txt\", timestamp=True, time_prefix=True)\n",
    "    print(f\"Prefix: {path2.name}\")\n",
    "\n",
    "    # Custom timestamp format\n",
    "    path3 = await acreate_path(tmpdir, \"report\", \"txt\", timestamp=True, timestamp_format=\"%Y-%m-%d\")\n",
    "    print(f\"Custom format: {path3.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T18:55:18.881096Z",
     "iopub.status.busy": "2025-11-23T18:55:18.881010Z",
     "iopub.status.idle": "2025-11-23T18:55:18.883990Z",
     "shell.execute_reply": "2025-11-23T18:55:18.883662Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path 1: session-b4b95fd6.log\n",
      "Path 2: session-0d122691.log\n",
      "Unique: True\n"
     ]
    }
   ],
   "source": [
    "# Random hash suffix for uniqueness\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    path1 = await acreate_path(tmpdir, \"session\", \"log\", random_hash_digits=8)\n",
    "    path2 = await acreate_path(tmpdir, \"session\", \"log\", random_hash_digits=8)\n",
    "\n",
    "    print(f\"Path 1: {path1.name}\")\n",
    "    print(f\"Path 2: {path2.name}\")\n",
    "    print(f\"Unique: {path1.name != path2.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T18:55:18.885075Z",
     "iopub.status.busy": "2025-11-23T18:55:18.884992Z",
     "iopub.status.idle": "2025-11-23T18:55:18.887801Z",
     "shell.execute_reply": "2025-11-23T18:55:18.887501Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full path: /var/folders/5p/rcbw097d29j3s2qt861tsjfh0000gn/T/tmpjvk82xxd/output/results_20251123-1ec64d.csv\n",
      "Filename: results_20251123-1ec64d.csv\n"
     ]
    }
   ],
   "source": [
    "# Combining timestamp + random hash\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    path = await acreate_path(\n",
    "        tmpdir,\n",
    "        \"output/results.csv\",\n",
    "        timestamp=True,\n",
    "        random_hash_digits=6,\n",
    "        timestamp_format=\"%Y%m%d\",\n",
    "    )\n",
    "    print(f\"Full path: {path}\")\n",
    "    print(f\"Filename: {path.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T18:55:18.889009Z",
     "iopub.status.busy": "2025-11-23T18:55:18.888925Z",
     "iopub.status.idle": "2025-11-23T18:55:18.892397Z",
     "shell.execute_reply": "2025-11-23T18:55:18.892036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ File exists error caught: FileExistsError\n",
      "✓ file_exist_ok=True allows existing: True\n"
     ]
    }
   ],
   "source": [
    "# File existence control\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    path = await acreate_path(tmpdir, \"unique\", \"txt\")\n",
    "\n",
    "    # Create the file\n",
    "    await path.touch()\n",
    "\n",
    "    # Try creating again with file_exist_ok=False (default)\n",
    "    try:\n",
    "        await acreate_path(tmpdir, \"unique.txt\", file_exist_ok=False)\n",
    "    except FileExistsError as e:\n",
    "        print(f\"✓ File exists error caught: {type(e).__name__}\")\n",
    "\n",
    "    # Allow existing file\n",
    "    path2 = await acreate_path(tmpdir, \"unique.txt\", file_exist_ok=True)\n",
    "    print(f\"✓ file_exist_ok=True allows existing: {path == path2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T18:55:18.893618Z",
     "iopub.status.busy": "2025-11-23T18:55:18.893552Z",
     "iopub.status.idle": "2025-11-23T18:55:18.896219Z",
     "shell.execute_reply": "2025-11-23T18:55:18.895678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Completed within timeout: fast.txt\n"
     ]
    }
   ],
   "source": [
    "# Timeout protection for slow I/O\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    # Normal operation completes quickly\n",
    "    path = await acreate_path(tmpdir, \"fast\", \"txt\", timeout=1.0)\n",
    "    print(f\"✓ Completed within timeout: {path.name}\")\n",
    "\n",
    "    # Note: Actual timeout demonstration would require slow filesystem\n",
    "    # In practice, typical operations complete in <100ms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 3. Bin Packing with get_bins()\n",
    "\n",
    "Organize string indices into bins by cumulative length - useful for batching within token limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T18:55:18.897688Z",
     "iopub.status.busy": "2025-11-23T18:55:18.897571Z",
     "iopub.status.idle": "2025-11-23T18:55:18.900218Z",
     "shell.execute_reply": "2025-11-23T18:55:18.899844Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strings: ['short', 'a bit longer', 'tiny', 'this is a much longer string', 'mid']\n",
      "\n",
      "Bins (max 20 chars cumulative):\n",
      "\n",
      "  Bin 0: indices [0, 1]\n",
      "    Strings: ['short', 'a bit longer']\n",
      "    Total length: 17\n",
      "  Bin 1: indices [2]\n",
      "    Strings: ['tiny']\n",
      "    Total length: 4\n",
      "  Bin 2: indices [3]\n",
      "    Strings: ['this is a much longer string']\n",
      "    Total length: 28\n",
      "  Bin 3: indices [4]\n",
      "    Strings: ['mid']\n",
      "    Total length: 3\n"
     ]
    }
   ],
   "source": [
    "# Basic binning\n",
    "strings = [\"short\", \"a bit longer\", \"tiny\", \"this is a much longer string\", \"mid\"]\n",
    "bins = get_bins(strings, upper=20)\n",
    "\n",
    "print(\"Strings:\", strings)\n",
    "print(\"\\nBins (max 20 chars cumulative):\\n\")\n",
    "for i, bin_indices in enumerate(bins):\n",
    "    bin_strings = [strings[idx] for idx in bin_indices]\n",
    "    total_len = sum(len(s) for s in bin_strings)\n",
    "    print(f\"  Bin {i}: indices {bin_indices}\")\n",
    "    print(f\"    Strings: {bin_strings}\")\n",
    "    print(f\"    Total length: {total_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T18:55:18.901272Z",
     "iopub.status.busy": "2025-11-23T18:55:18.901196Z",
     "iopub.status.idle": "2025-11-23T18:55:18.903686Z",
     "shell.execute_reply": "2025-11-23T18:55:18.903222Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organizing messages into batches:\n",
      "\n",
      "Batch 1: ['Hello', 'How are you?']\n",
      "Batch 2: [\"I'm doing great!\"]\n",
      "Batch 3: [\"What's the weather like?\", 'Sunny']\n",
      "Batch 4: ['Perfect!']\n"
     ]
    }
   ],
   "source": [
    "# Token limit simulation\n",
    "messages = [\n",
    "    \"Hello\",\n",
    "    \"How are you?\",\n",
    "    \"I'm doing great!\",\n",
    "    \"What's the weather like?\",\n",
    "    \"Sunny\",\n",
    "    \"Perfect!\",\n",
    "]\n",
    "\n",
    "# Bin by 30-character chunks\n",
    "bins = get_bins(messages, upper=30)\n",
    "\n",
    "print(\"Organizing messages into batches:\\n\")\n",
    "for i, bin_indices in enumerate(bins):\n",
    "    batch = [messages[idx] for idx in bin_indices]\n",
    "    print(f\"Batch {i + 1}: {batch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cell-16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T18:55:18.904667Z",
     "iopub.status.busy": "2025-11-23T18:55:18.904592Z",
     "iopub.status.idle": "2025-11-23T18:55:18.906932Z",
     "shell.execute_reply": "2025-11-23T18:55:18.906480Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When item > limit, it gets its own bin:\n",
      "\n",
      "Bin 0: ['a']\n",
      "Bin 1: ['this exceeds the limit by far']\n",
      "Bin 2: ['b', 'c']\n"
     ]
    }
   ],
   "source": [
    "# Edge case: String longer than limit\n",
    "items = [\"a\", \"this exceeds the limit by far\", \"b\", \"c\"]\n",
    "bins = get_bins(items, upper=10)\n",
    "\n",
    "print(\"When item > limit, it gets its own bin:\\n\")\n",
    "for i, bin_indices in enumerate(bins):\n",
    "    print(f\"Bin {i}: {[items[idx] for idx in bin_indices]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## 4. Dynamic Imports with import_module()\n",
    "\n",
    "Import modules, packages, and specific objects dynamically by path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cell-18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T18:55:18.908027Z",
     "iopub.status.busy": "2025-11-23T18:55:18.907948Z",
     "iopub.status.idle": "2025-11-23T18:55:18.910104Z",
     "shell.execute_reply": "2025-11-23T18:55:18.909547Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported: json\n",
      "Has dumps: True\n"
     ]
    }
   ],
   "source": [
    "# Import entire module\n",
    "json_module = import_module(\"json\")\n",
    "print(f\"Imported: {json_module.__name__}\")\n",
    "print(f\"Has dumps: {hasattr(json_module, 'dumps')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cell-19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T18:55:18.911339Z",
     "iopub.status.busy": "2025-11-23T18:55:18.911234Z",
     "iopub.status.idle": "2025-11-23T18:55:18.913437Z",
     "shell.execute_reply": "2025-11-23T18:55:18.913078Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported: Path\n",
      "Type: <class 'type'>\n",
      "Created path: /tmp/test\n"
     ]
    }
   ],
   "source": [
    "# Import specific object from module\n",
    "PathClass = import_module(\"pathlib\", import_name=\"Path\")\n",
    "print(f\"Imported: {PathClass.__name__}\")\n",
    "print(f\"Type: {type(PathClass)}\")\n",
    "\n",
    "# Use it\n",
    "p = PathClass(\"/tmp/test\")\n",
    "print(f\"Created path: {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cell-20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T18:55:18.914518Z",
     "iopub.status.busy": "2025-11-23T18:55:18.914446Z",
     "iopub.status.idle": "2025-11-23T18:55:18.916941Z",
     "shell.execute_reply": "2025-11-23T18:55:18.916619Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported: dumps, loads\n",
      "Roundtrip: {'test': 123} -> '{\"test\": 123}' -> {'test': 123}\n"
     ]
    }
   ],
   "source": [
    "# Import multiple objects at once\n",
    "dumps, loads = import_module(\"json\", import_name=[\"dumps\", \"loads\"])\n",
    "print(f\"Imported: {dumps.__name__}, {loads.__name__}\")\n",
    "\n",
    "# Use them\n",
    "data = {\"test\": 123}\n",
    "json_str = dumps(data)\n",
    "restored = loads(json_str)\n",
    "print(f\"Roundtrip: {data} -> '{json_str}' -> {restored}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cell-21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T18:55:18.917970Z",
     "iopub.status.busy": "2025-11-23T18:55:18.917904Z",
     "iopub.status.idle": "2025-11-23T18:55:18.919966Z",
     "shell.execute_reply": "2025-11-23T18:55:18.919679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported: Element\n",
      "Created: Element with ID 359e9461-73d5-4d91-854a-d2ece074ccd0\n"
     ]
    }
   ],
   "source": [
    "# Import from nested package\n",
    "Element = import_module(\"lionpride.core\", import_name=\"Element\")\n",
    "print(f\"Imported: {Element.__name__}\")\n",
    "\n",
    "# Create instance\n",
    "elem = Element()\n",
    "print(f\"Created: {type(elem).__name__} with ID {elem.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cell-22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T18:55:18.921030Z",
     "iopub.status.busy": "2025-11-23T18:55:18.920957Z",
     "iopub.status.idle": "2025-11-23T18:55:18.923094Z",
     "shell.execute_reply": "2025-11-23T18:55:18.922687Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Import error caught: Failed to import module nonexistent_package_xyz: N...\n"
     ]
    }
   ],
   "source": [
    "# Error handling for missing modules\n",
    "try:\n",
    "    import_module(\"nonexistent_package_xyz\")\n",
    "except ImportError as e:\n",
    "    print(f\"✓ Import error caught: {str(e)[:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## 5. Package Detection with is_import_installed()\n",
    "\n",
    "Check if packages are available before attempting imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cell-24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T18:55:18.924036Z",
     "iopub.status.busy": "2025-11-23T18:55:18.923973Z",
     "iopub.status.idle": "2025-11-23T18:55:18.925869Z",
     "shell.execute_reply": "2025-11-23T18:55:18.925491Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json installed: True\n",
      "pathlib installed: True\n",
      "asyncio installed: True\n"
     ]
    }
   ],
   "source": [
    "# Check standard library\n",
    "print(f\"json installed: {is_import_installed('json')}\")\n",
    "print(f\"pathlib installed: {is_import_installed('pathlib')}\")\n",
    "print(f\"asyncio installed: {is_import_installed('asyncio')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cell-25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T18:55:18.926720Z",
     "iopub.status.busy": "2025-11-23T18:55:18.926662Z",
     "iopub.status.idle": "2025-11-23T18:55:18.928726Z",
     "shell.execute_reply": "2025-11-23T18:55:18.928217Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pydantic installed: True\n",
      "anyio installed: True\n"
     ]
    }
   ],
   "source": [
    "# Check third-party packages\n",
    "print(f\"pydantic installed: {is_import_installed('pydantic')}\")\n",
    "print(f\"anyio installed: {is_import_installed('anyio')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cell-26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T18:55:18.929781Z",
     "iopub.status.busy": "2025-11-23T18:55:18.929711Z",
     "iopub.status.idle": "2025-11-23T18:55:18.931583Z",
     "shell.execute_reply": "2025-11-23T18:55:18.931238Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fake_package_xyz installed: False\n"
     ]
    }
   ],
   "source": [
    "# Check non-existent package\n",
    "print(f\"fake_package_xyz installed: {is_import_installed('fake_package_xyz')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cell-27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T18:55:18.932491Z",
     "iopub.status.busy": "2025-11-23T18:55:18.932426Z",
     "iopub.status.idle": "2025-11-23T18:55:18.934144Z",
     "shell.execute_reply": "2025-11-23T18:55:18.933810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Pydantic available, using BaseModel\n"
     ]
    }
   ],
   "source": [
    "# Conditional import pattern\n",
    "if is_import_installed(\"pydantic\"):\n",
    "    print(\"✓ Pydantic available, using BaseModel\")\n",
    "else:\n",
    "    print(\"⚠ Pydantic not available, using alternative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": [
    "## 6. Real-World Use Cases\n",
    "\n",
    "Combining utilities for common patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cell-29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T18:55:18.935087Z",
     "iopub.status.busy": "2025-11-23T18:55:18.935023Z",
     "iopub.status.idle": "2025-11-23T18:55:18.938531Z",
     "shell.execute_reply": "2025-11-23T18:55:18.938178Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log file: session_20251123_135518-a8c1.log\n",
      "Content: [2025-11-23T18:55:18.936501+00:00] Session started\n"
     ]
    }
   ],
   "source": [
    "# Timestamped log file creation\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    log_path = await acreate_path(\n",
    "        tmpdir,\n",
    "        \"sessions/session\",\n",
    "        \"log\",\n",
    "        timestamp=True,\n",
    "        random_hash_digits=4,\n",
    "        timestamp_format=\"%Y%m%d_%H%M%S\",\n",
    "    )\n",
    "\n",
    "    # Write timestamped entry\n",
    "    await log_path.write_text(f\"[{now_utc().isoformat()}] Session started\\n\")\n",
    "\n",
    "    content = await log_path.read_text()\n",
    "    print(f\"Log file: {log_path.name}\")\n",
    "    print(f\"Content: {content.strip()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cell-30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T18:55:18.939623Z",
     "iopub.status.busy": "2025-11-23T18:55:18.939560Z",
     "iopub.status.idle": "2025-11-23T18:55:18.941917Z",
     "shell.execute_reply": "2025-11-23T18:55:18.941452Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing message batches:\n",
      "\n",
      "[18:55:18] Batch 1: 2 messages\n",
      "  - User: Hello\n",
      "  - Assistant: Hi there!\n",
      "[18:55:18] Batch 2: 1 messages\n",
      "  - User: How's the weather?\n",
      "[18:55:18] Batch 3: 2 messages\n",
      "  - Assistant: Sunny and warm!\n",
      "  - User: Great for a walk\n",
      "[18:55:18] Batch 4: 1 messages\n",
      "  - Assistant: Absolutely!\n"
     ]
    }
   ],
   "source": [
    "# Batch message processing with token limits\n",
    "messages = [\n",
    "    \"User: Hello\",\n",
    "    \"Assistant: Hi there!\",\n",
    "    \"User: How's the weather?\",\n",
    "    \"Assistant: Sunny and warm!\",\n",
    "    \"User: Great for a walk\",\n",
    "    \"Assistant: Absolutely!\",\n",
    "]\n",
    "\n",
    "# Organize into batches (simulate 50-char token limit)\n",
    "bins = get_bins(messages, upper=50)\n",
    "\n",
    "print(\"Processing message batches:\\n\")\n",
    "for i, bin_indices in enumerate(bins):\n",
    "    batch = [messages[idx] for idx in bin_indices]\n",
    "    timestamp = now_utc()\n",
    "    print(f\"[{timestamp.strftime('%H:%M:%S')}] Batch {i + 1}: {len(batch)} messages\")\n",
    "    for msg in batch:\n",
    "        print(f\"  - {msg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cell-31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T18:55:18.942869Z",
     "iopub.status.busy": "2025-11-23T18:55:18.942807Z",
     "iopub.status.idle": "2025-11-23T18:55:18.945740Z",
     "shell.execute_reply": "2025-11-23T18:55:18.945297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using serializer: orjson\n",
      "Serialized: b'{\"timestamp\":\"2025-11-23T18:55:18.943825+00:00\",\"status\":\"ok\"}'\n"
     ]
    }
   ],
   "source": [
    "# Optional feature loading with graceful fallback\n",
    "def get_serializer():\n",
    "    \"\"\"Get best available JSON serializer.\"\"\"\n",
    "    if is_import_installed(\"orjson\"):\n",
    "        orjson = import_module(\"orjson\")\n",
    "        return \"orjson\", orjson.dumps, orjson.loads\n",
    "    else:\n",
    "        json = import_module(\"json\")\n",
    "        return \"json\", json.dumps, json.loads\n",
    "\n",
    "\n",
    "name, dumps, loads = get_serializer()\n",
    "print(f\"Using serializer: {name}\")\n",
    "\n",
    "# Test it\n",
    "data = {\"timestamp\": now_utc().isoformat(), \"status\": \"ok\"}\n",
    "serialized = dumps(data)\n",
    "print(f\"Serialized: {serialized}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-32",
   "metadata": {},
   "source": [
    "## Summary Checklist\n",
    "\n",
    "**Time Utilities:**\n",
    "- ✅ `now_utc()` for consistent UTC timestamps\n",
    "- ✅ Timezone-aware datetime objects\n",
    "\n",
    "**Path Management:**\n",
    "- ✅ `acreate_path()` for async file path creation\n",
    "- ✅ Subdirectory support via `/` in filename\n",
    "- ✅ Optional timestamps (prefix/suffix, custom format)\n",
    "- ✅ Random hash suffixes for uniqueness\n",
    "- ✅ File existence control\n",
    "- ✅ Timeout protection for I/O operations\n",
    "\n",
    "**Data Organization:**\n",
    "- ✅ `get_bins()` for batching strings by cumulative length\n",
    "- ✅ Useful for token limits, message batching\n",
    "\n",
    "**Dynamic Imports:**\n",
    "- ✅ `import_module()` for runtime imports\n",
    "- ✅ Import entire modules or specific objects\n",
    "- ✅ Multiple object imports in one call\n",
    "- ✅ `is_import_installed()` for availability checks\n",
    "- ✅ Graceful fallbacks for optional dependencies\n",
    "\n",
    "**Common Patterns:**\n",
    "- ✅ Timestamped log files with unique IDs\n",
    "- ✅ Batch processing with size limits\n",
    "- ✅ Optional feature loading with fallbacks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lionpride",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
